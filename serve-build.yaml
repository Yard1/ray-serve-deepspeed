# This file was generated using the `serve build` command on Ray v3.0.0.dev0.

import_path: deepspeed_app:entrypoint

runtime_env: 
  env_vars:
    HF_HOME: "/nvme/cache"

host: 0.0.0.0

port: 8000

deployments:

- name: LLMDeployment
  max_concurrent_queries: 20
  autoscaling_config:
    min_replicas: 2
    initial_replicas: 2
    max_replicas: 8
    target_num_ongoing_requests_per_replica: 1.0
    metrics_interval_s: 10.0
    look_back_period_s: 30.0
    smoothing_factor: 1.0
    downscale_delay_s: 300.0
    upscale_delay_s: 30.0
  ray_actor_options:
    resources:
      worker_node: 0.5
  user_config:
    hf_home: /nvme/cache
    model_config:
      max_batch_size: 20
      dtype: float16
      from_pretrained_kwargs: {}
      generation_kwargs:
        do_sample: true
        max_new_tokens: 256
        top_k: 0
        top_p: 0.92
      mirror_bucket_uri: s3://large-dl-models-mirror/models--stabilityai--stablelm-tuned-alpha-7b/main/
      mode:
        type: DeepSpeed
        use_kernel: true
      name: stabilityai/stablelm-tuned-alpha-7b
      pipeline_cls: stablelm
      prompt_format: null
      stopping_tokens: null
    scaling_config:
      num_workers: 2
      num_gpus_per_worker: 1
      num_cpus_per_worker: 4

- name: LLMDeployment_1
  max_concurrent_queries: 8
  autoscaling_config:
    min_replicas: 2
    initial_replicas: 2
    max_replicas: 8
    target_num_ongoing_requests_per_replica: 1.0
    metrics_interval_s: 10.0
    look_back_period_s: 30.0
    smoothing_factor: 1.0
    downscale_delay_s: 300.0
    upscale_delay_s: 30.0
  ray_actor_options:
    resources:
      worker_node: 0.5
  user_config:
    hf_home: /nvme/cache
    model_config:
      max_batch_size: 8
      dtype: float16
      from_pretrained_kwargs: {}
      generation_kwargs:
        do_sample: true
        max_new_tokens: 256
        top_k: 0
        top_p: 0.92
      mirror_bucket_uri: s3://large-dl-models-mirror/models--diegi97--dolly-v2-12b-sharded-bf16/main/
      mode:
        type: DeepSpeed
        use_kernel: false
      name: diegi97/dolly-v2-12b-sharded-bf16
      pipeline_cls: dollyv2
      prompt_format: null
      stopping_tokens: null
    scaling_config:
      num_workers: 2
      num_gpus_per_worker: 1
      num_cpus_per_worker: 4

- name: RouterDeployment
  route_prefix: /
